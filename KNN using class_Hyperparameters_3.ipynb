{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e33654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d83f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        self.k = k\n",
    "\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        predictions = [self._predict(x) for x in X_test]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        if distance_matrix == 'Euclidean':\n",
    "            distances = [np.sqrt(np.sum((x - x_train)**2)) for x_train in self.X_train]\n",
    "        elif distance_matrix == 'Manhattan':\n",
    "            distances = [np.sum(np.abs(x - x_train)) for x_train in self.X_train]\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "\n",
    "        label_counts = {}\n",
    "        for label in k_nearest_labels:\n",
    "            if label in label_counts:\n",
    "                label_counts[label] += 1\n",
    "            else:\n",
    "                label_counts[label] = 1\n",
    "\n",
    "        most_common_label = max(label_counts, key=label_counts.get)\n",
    "\n",
    "        return most_common_label\n",
    "    \n",
    "    # def train_test_split(self, X, y, test_size=0.2, random_state=None):\n",
    "    #     if random_state is not None:\n",
    "    #         np.random.seed(random_state)\n",
    "        \n",
    "    #     num_samples = X.shape[0]\n",
    "    #     num_test_samples = int(num_samples * test_size)\n",
    "    #     shuffled_indices = np.random.permutation(num_samples)\n",
    "        \n",
    "    #     X_shuffled = X[shuffled_indices]\n",
    "    #     y_shuffled = y[shuffled_indices]\n",
    "        \n",
    "    #     X_train = X_shuffled[:-num_test_samples]\n",
    "    #     y_train = y_shuffled[:-num_test_samples]\n",
    "    #     X_test = X_shuffled[-num_test_samples:]\n",
    "    #     y_test = y_shuffled[-num_test_samples:]\n",
    "        \n",
    "    #     return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    # def accuracy(self, y_pred, y_true):\n",
    "    #     correct_predictions = np.sum(y_pred == y_true)\n",
    "    #     total_predictions = len(y_pred)\n",
    "    #     accuracy = correct_predictions / total_predictions\n",
    "    #     return accuracy\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "\n",
    "#num_samples = 1500\n",
    "#num_features = 1024\n",
    "#X_train = np.random.randn(num_samples, num_features)\n",
    "#y_train = np.random.randint(2, size=num_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d66ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import extra\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b87ea82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 amal\n",
      "1 janak\n",
      "2 amal\n",
      "2 janak\n",
      "3 amal\n",
      "3 janak\n"
     ]
    }
   ],
   "source": [
    "parameter = {\n",
    "    'k' : [1, 2, 3],\n",
    "    'name' : ['amal', 'janak']\n",
    "}\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "ll = list(product(*parameter.values()))\n",
    "for l in ll:\n",
    "     print(*l)\n",
    "    #core.KNN(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be7074f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ed1d9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 1024)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'distance_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m extra\u001b[39m.\u001b[39mtrain_test_split(X_train, y_train, test_size\u001b[39m=\u001b[39m\u001b[39m0.20\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m     27\u001b[0m myknn\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m---> 28\u001b[0m predictions \u001b[39m=\u001b[39m myknn\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[0;32m     30\u001b[0m accuracy \u001b[39m=\u001b[39m extra\u001b[39m.\u001b[39maccuracy(predictions, y_test)\n\u001b[0;32m     31\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAccuracy:\u001b[39m\u001b[39m\"\u001b[39m, accuracy,\u001b[39m'\u001b[39m\u001b[39mK =\u001b[39m\u001b[39m'\u001b[39m,k,encoder,distance_matrix)\n",
      "File \u001b[1;32mc:\\Users\\JANAKSINH\\SMAI_assignment_1\\core.py:14\u001b[0m, in \u001b[0;36mKNN.predict\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X_test):\n\u001b[1;32m---> 14\u001b[0m     predictions \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predict(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X_test]\n\u001b[0;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(predictions)\n",
      "File \u001b[1;32mc:\\Users\\JANAKSINH\\SMAI_assignment_1\\core.py:14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X_test):\n\u001b[1;32m---> 14\u001b[0m     predictions \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X_test]\n\u001b[0;32m     15\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray(predictions)\n",
      "File \u001b[1;32mc:\\Users\\JANAKSINH\\SMAI_assignment_1\\core.py:18\u001b[0m, in \u001b[0;36mKNN._predict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 18\u001b[0m     \u001b[39mif\u001b[39;00m distance_matrix \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mEuclidean\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     19\u001b[0m         distances \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39msqrt(np\u001b[39m.\u001b[39msum((x \u001b[39m-\u001b[39m x_train)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)) \u001b[39mfor\u001b[39;00m x_train \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_train]\n\u001b[0;32m     20\u001b[0m     \u001b[39melif\u001b[39;00m distance_matrix \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mManhattan\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'distance_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import extra\n",
    "import core\n",
    "\n",
    "k_list = [1,2,3,4,5,6,7,8,9,10,11,12.13]\n",
    "encoder_list = ['RESNET', 'VIT']\n",
    "distance_matrix_list = ['Euclidean', 'Manhattan']\n",
    "\n",
    "for k in k_list:\n",
    "    for encoder in encoder_list:\n",
    "        for distance_matrix in distance_matrix_list:\n",
    "            dataset = np.load(\"data.npy\",allow_pickle=True)\n",
    "            if encoder == 'RESNET':\n",
    "                X_train = dataset[:,1]  # Load your data\n",
    "                X_train = np.concatenate([item.flatten() for item in X_train]).reshape(1500, 1024)     #for RESNETs 1st column\n",
    "                print(X_train.shape)\n",
    "            elif encoder == 'VIT':\n",
    "                X_train = dataset[:,2]  # Load your data\n",
    "                X_train = np.concatenate([item.flatten() for item in X_train]).reshape(1500, 512)      #for VITs 2nd column\n",
    "                print(X_train.shape)\n",
    "            y_train = dataset[:,3] \n",
    "            \n",
    "            \n",
    "            myknn = core.KNN(k)\n",
    "            X_train, X_test, y_train, y_test = extra.train_test_split(X_train, y_train, test_size=0.20, random_state=42)\n",
    "\n",
    "            myknn.fit(X_train, y_train)\n",
    "            predictions = myknn.predict(X_test)\n",
    "\n",
    "            accuracy = extra.accuracy(predictions, y_test)\n",
    "            print(\"Accuracy:\", accuracy,'K =',k,encoder,distance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbfbc28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
